{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dataset annotator using SAM. For every image in the datset, it allows the user to mannually draw bounding boxes on images, generate masks, ans convert them into YOLO format for training purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator\n",
    "import torch\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'my_custom_dataset'\n",
    "os.makedirs(dataset_name, exist_ok=True)\n",
    "images_folder_path = \"test_images\"\n",
    "train_split_path = dataset_name + \"/train\"\n",
    "train_images_folder_path = train_split_path + \"/images\"\n",
    "train_labels_folder_path = train_split_path + \"/labels\"\n",
    "os.makedirs(train_images_folder_path, exist_ok=True)\n",
    "os.makedirs(train_labels_folder_path, exist_ok=True)\n",
    "\n",
    "val_split_path = dataset_name + \"/valid\"\n",
    "test_split_path = dataset_name + \"/test\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [f for f in os.listdir(images_folder_path) if os.path.isfile(os.path.join(images_folder_path, f))]\n",
    "image_number = 0\n",
    "for image_file in image_files:\n",
    "    image_number += 1\n",
    "    image_path = os.path.join(images_folder_path, image_file)\n",
    "    img = cv2.imread(image_path)\n",
    "    cv2.imwrite(train_split_path + \"/images/\" + str(image_number) + \".png\", img)\n",
    "    r = {}\n",
    "    while(True):\n",
    "        label = input(\"Enter the label for the mask (exit to move to net image): \")\n",
    "        if label == 'exit':\n",
    "            break\n",
    "        if label not in r:\n",
    "            r[label] = {\"bounding_box\": [], \"masks\": []}\n",
    "        while True:\n",
    "            bbox = cv2.selectROI(\"Interactive Menu\", img)\n",
    "        \n",
    "            convert = [bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3]]\n",
    "            r[label][\"bounding_box\"].append(np.asarray(convert))\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "            cont = input(\"Draw another bounding box for the same label? (y/n): \")\n",
    "            if cont.lower() != 'y':\n",
    "                break  # Move to the next label\n",
    "\n",
    "\n",
    "    print(\"\\nSegmenting the objects, this might take a while\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    sam = sam_model_registry[\"vit_h\"](checkpoint=\"sam_vit_h_4b8939.pth\")\n",
    "    # sam.to(device)\n",
    "    mask_predictor = SamPredictor(sam)\n",
    "    img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mask_predictor.set_image(img2)\n",
    "\n",
    "    for label in r:\n",
    "        for bbox in r[label][\"bounding_box\"]:\n",
    "            mask, _, _ = mask_predictor.predict(box=bbox, multimask_output=False)\n",
    "            r[label][\"masks\"].append(mask[0])\n",
    "\n",
    "    # mask_visualization = np.zeros_like(img)\n",
    "    # for label in r:\n",
    "    #     color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "    #     for mask in r[label][\"masks\"]:\n",
    "    #         mask_visualization[mask] = color\n",
    "\n",
    "    # plt.imshow(mask_visualization)\n",
    "    # plt.show()\n",
    "\n",
    "    color_mask = np.zeros_like(img)\n",
    "    with open(train_split_path + \"/labels/\" + str(image_number) + \".txt\", \"w\") as f:\n",
    "        for label in r:\n",
    "            for mask in r[label][\"masks\"]:\n",
    "                mask[mask > 0] = 255\n",
    "                mask = mask.astype(np.uint8)\n",
    "                contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                approx_contours = [cv2.approxPolyDP(contour, 0.001 * cv2.arcLength(contour, True), True) for contour in contours]\n",
    "                color = [int(c) for c in np.random.choice(range(256), size=3)]\n",
    "                for i, contour in enumerate(approx_contours):\n",
    "                    f.write(str(label) + \" \")\n",
    "                    for point in contour:\n",
    "                        f.write(str(point[0][0]/img.shape[0]) + \" \" + str(point[0][1]/img.shape[1]) + \" \")\n",
    "                    f.write(\"\\n\")\n",
    "                    cv2.drawContours(color_mask, [contour], -1, color, 2)\n",
    "    # for label in r:\n",
    "    #     for mask in r[label][\"masks\"]:\n",
    "    #         mask[mask > 0] = 255\n",
    "    #         mask = mask.astype(np.uint8)\n",
    "    #         contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #         approx_contours = [cv2.approxPolyDP(contour, 0.001 * cv2.arcLength(contour, True), True) for contour in contours]\n",
    "    #         color = [int(c) for c in np.random.choice(range(256), size=3)]  # Random color for each instance\n",
    "    #         for i, contour in enumerate(approx_contours):\n",
    "    #             cv2.drawContours(color_mask, [contour], -1, color, 2)  # Fill the contour with the color\n",
    "    #             for point in contour:\n",
    "    #                 print(point[0][0], point[0][1])\n",
    "\n",
    "    plt.imshow(color_mask)\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
